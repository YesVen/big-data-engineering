What is streaming access pattern?
Write once and read any number of times but don't try to change the content of the file once you are keeping in the HDFS.

On top of Hard disk we are creating HDFS. It is built on top of normal file system.
Default Block size is 64MB
So for processing huge datasets Haoop is using 64MB block size and not default block size of 4Kb on hard disk.

**
Extra: Hard disk consists of blocks on one sector and one block is 4KB. There are several sectorsin Hard disk. 
If i try to save 2 KB of file than 2 KB will be wasted.
Hadoop Administrator should take care of this HDFS and its configuration and not developers.
**
So if you store a file of size 35MB than 29MB won't be wasted by Hadoop but it will be released for other files.
Eg: for 500 GB hard disk, 7500 blocks will be given.
-----------------------------------------------------------------------------------------------------------------

Hadoop Architecture

Master Services: They can talk to each other. Eg: NN can talk to SNN, JT. NN can talk to it's corresponding DN and vice versa but not to TT.
Name node,(NN)
Secondary Name node,(SNN)
Job Tracker(JT)

Slave Services: Similarly, TT can talk to JT and vice versa. TT can talk to DN.
Data node,(DN)
Task Tracker(TT)

------------------------------------------------------------------------------------------------------------------

Example scenario
So we are going to store a file name file.txt 200 MB of file on Hadoop.
So 4 blocks will be given to this 200 MB file. 64*3 + 8MB = 200MB.
So NN will take care of splitting this 200MB of file into 64MB blocks.

So NN acts as a Manager and client sends a request to NN. It stores the metadata about the file name file.txt
1) NN receives the request and stores details in its meta data. 
   Details like 4 files will be created named a.txt, b.txt, c.txt --> 64MB 
   and d.txt --> 8MB.
2) So NN says to client that please go and store your file in DN number 1,3,5,7
   So now the clientvery well knows which DN are having free space. So now client is directly approaching these systems.
3) So now the client is approaching DN1 and keeping the a.txt file there.

**
Extra: So all these DN are cheap commodity hardwares, so every DN will be there with 300 or 500GB of HD capacity for example.
If it is 500Gb HD than 7500 blocks will be there.
